{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<p style=\"align: center;\"><img style=\"align: center; border-radius: 10px;\" align=center src=\"https://sun9-32.userapi.com/impf/MmYC-5xp1ziyMkUdVkKVul8c2lCvmY7b4VTjtw/EekxnCmkVGM.jpg?size=1818x606&quality=95&crop=0,140,960,320&sign=7e803728a35685a6605e03a5da104e34&type=cover_group\" width=1200 height=480></p>\n",
    "<h1 style=\"text-align: center;\"><b>Segmentation part of AGNI CV summer 2023</b></h1>\n",
    "\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install torchsummary"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-07T21:46:27.050042Z",
     "iopub.execute_input": "2023-07-07T21:46:27.050686Z",
     "iopub.status.idle": "2023-07-07T21:46:56.200115Z",
     "shell.execute_reply.started": "2023-07-07T21:46:27.050655Z",
     "shell.execute_reply": "2023-07-07T21:46:56.198905Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-07-07T22:14:25.275479Z",
     "start_time": "2023-07-07T22:13:58.057734800Z"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in c:\\users\\dimka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.5.1)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\dimka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (23.1.2)\n",
      "Requirement already satisfied: segmentation-models-pytorch in c:\\users\\dimka\\appdata\\roaming\\python\\python39\\site-packages (0.3.3)\n",
      "Requirement already satisfied: albumentations in c:\\users\\dimka\\appdata\\roaming\\python\\python39\\site-packages (1.3.1)\n",
      "Requirement already satisfied: torchvision>=0.5.0 in c:\\users\\dimka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from segmentation-models-pytorch) (0.14.1)\n",
      "Requirement already satisfied: pretrainedmodels==0.7.4 in c:\\users\\dimka\\appdata\\roaming\\python\\python39\\site-packages (from segmentation-models-pytorch) (0.7.4)\n",
      "Requirement already satisfied: efficientnet-pytorch==0.7.1 in c:\\users\\dimka\\appdata\\roaming\\python\\python39\\site-packages (from segmentation-models-pytorch) (0.7.1)\n",
      "Requirement already satisfied: timm==0.9.2 in c:\\users\\dimka\\appdata\\roaming\\python\\python39\\site-packages (from segmentation-models-pytorch) (0.9.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dimka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from segmentation-models-pytorch) (4.64.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\dimka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from segmentation-models-pytorch) (9.4.0)\n",
      "Requirement already satisfied: torch in c:\\users\\dimka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.13.1+cu117)\n",
      "Requirement already satisfied: munch in c:\\users\\dimka\\appdata\\roaming\\python\\python39\\site-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch) (4.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\dimka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from timm==0.9.2->segmentation-models-pytorch) (6.0)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\dimka\\appdata\\roaming\\python\\python39\\site-packages (from timm==0.9.2->segmentation-models-pytorch) (0.16.4)\n",
      "Requirement already satisfied: safetensors in c:\\users\\dimka\\appdata\\roaming\\python\\python39\\site-packages (from timm==0.9.2->segmentation-models-pytorch) (0.3.1)\n",
      "Requirement already satisfied: numpy>=1.11.1 in c:\\users\\dimka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from albumentations) (1.21.6)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\dimka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from albumentations) (1.9.1)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in c:\\users\\dimka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from albumentations) (0.20.0)\n",
      "Requirement already satisfied: qudida>=0.0.4 in c:\\users\\dimka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from albumentations) (0.0.4)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in c:\\users\\dimka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from albumentations) (4.7.0.72)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in c:\\users\\dimka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from qudida>=0.0.4->albumentations) (1.2.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\dimka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from qudida>=0.0.4->albumentations) (4.5.0)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\dimka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (3.1)\n",
      "Requirement already satisfied: imageio>=2.4.1 in c:\\users\\dimka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (2.28.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\dimka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (2023.4.12)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\dimka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (1.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dimka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (23.1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\dimka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\dimka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (2.29.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dimka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm->segmentation-models-pytorch) (0.4.6)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\dimka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dimka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\dimka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (3.12.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\dimka\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (2023.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dimka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dimka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dimka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dimka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2022.12.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U segmentation-models-pytorch albumentations --user"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-07T22:14:54.514980200Z",
     "start_time": "2023-07-07T22:14:25.201566Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as tt\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import multiprocessing as mp\n",
    "from PIL import Image\n",
    "\n",
    "import albumentations \n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "import segmentation_models_pytorch.utils.metrics"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2023-07-07T21:46:56.202464Z",
     "iopub.execute_input": "2023-07-07T21:46:56.202859Z",
     "iopub.status.idle": "2023-07-07T21:47:03.175605Z",
     "shell.execute_reply.started": "2023-07-07T21:46:56.202821Z",
     "shell.execute_reply": "2023-07-07T21:47:03.174600Z"
    },
    "trusted": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class GladeDataset(Dataset):\n",
    "    \"\"\" Dataset for Glade Segmentation \"\"\"\n",
    "    \n",
    "    def __init__(self, path, input_transform=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.path = path\n",
    "        self.input_transform = input_transform\n",
    "        self.to_tensor = ToTensor()\n",
    "        \n",
    "        self.names_of_files = [i.rsplit(\".\", 1)[0] for i in os.listdir(self.path) if i.endswith(\".jpg\")]\n",
    "  \n",
    "        self.data = []\n",
    "\n",
    "        \n",
    "        self._read_images()\n",
    "        \n",
    "    def _read_image(self, image_name):\n",
    "        \"\"\" Read image and use input_transforms \"\"\"\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(os.path.join(\n",
    "                self.path, \n",
    "                image_name + \".jpg\")\n",
    "            )\n",
    "\n",
    "            mask = Image.open(os.path.join(\n",
    "                self.path, \n",
    "                image_name + \"_mask.png\")\n",
    "            )\n",
    "\n",
    "            if self.input_transform:\n",
    "                transformed = self.input_transform(image=np.array(image), mask=np.array(mask))\n",
    "                image = transformed[\"image\"]\n",
    "                mask = transformed[\"mask\"]\n",
    "            \n",
    "            image = image.float()/255\n",
    "            mask = mask.float()\n",
    "\n",
    "            return image, mask\n",
    "        \n",
    "        except FileNotFoundError:\n",
    "            print(self.path + image_name + \".jpg\",\n",
    "                  self.path + image_name + \"_mask.png\", \n",
    "                  end=\"\\n\")\n",
    "    \n",
    "    def _read_images(self):\n",
    "        \"\"\" Pool of _read_image functions \"\"\"\n",
    "        \n",
    "        with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "            self.data = list(\n",
    "                tqdm(\n",
    "                    pool.imap_unordered(self._read_image, self.names_of_files),\n",
    "                    total=len(self.names_of_files)\n",
    "                )\n",
    "            )\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "            \n",
    "    def __len__(self):\n",
    "        \"\"\" Return lenght of dataset\"\"\"\n",
    "        \n",
    "        return len(self.data)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-07T21:47:03.177193Z",
     "iopub.execute_input": "2023-07-07T21:47:03.177552Z",
     "iopub.status.idle": "2023-07-07T21:47:03.407785Z",
     "shell.execute_reply.started": "2023-07-07T21:47:03.177518Z",
     "shell.execute_reply": "2023-07-07T21:47:03.406311Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-07-07T22:15:18.548496400Z",
     "start_time": "2023-07-07T22:15:18.473736900Z"
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def to_device(data, device):\n",
    "        \"\"\"\n",
    "        Move data to self.device\n",
    "        \"\"\"\n",
    "        if isinstance(data, (list, tuple)):\n",
    "            return [to_device(x, device) for x in data]\n",
    "        \n",
    "        return data.to(device, non_blocking=True)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-07T21:47:03.410661Z",
     "iopub.execute_input": "2023-07-07T21:47:03.412684Z",
     "iopub.status.idle": "2023-07-07T21:47:03.429756Z",
     "shell.execute_reply.started": "2023-07-07T21:47:03.412647Z",
     "shell.execute_reply": "2023-07-07T21:47:03.428696Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-07-07T22:15:18.587364Z",
     "start_time": "2023-07-07T22:15:18.515766600Z"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class DeviceDataLoader():\n",
    "    \"\"\" Dataloader that moving images to device \"\"\"\n",
    "    \n",
    "    def __init__(self, dataloader, device):\n",
    "        self.dataloader = dataloader\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for image_batch, mask_batch in self.dataloader:\n",
    "            yield to_device(image_batch, self.device), to_device(mask_batch, self.device)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataloader)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-07T21:47:03.431170Z",
     "iopub.execute_input": "2023-07-07T21:47:03.431956Z",
     "iopub.status.idle": "2023-07-07T21:47:03.443793Z",
     "shell.execute_reply.started": "2023-07-07T21:47:03.431922Z",
     "shell.execute_reply": "2023-07-07T21:47:03.442767Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-07-07T22:15:18.637618600Z",
     "start_time": "2023-07-07T22:15:18.548496400Z"
    }
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_dataloader(dataset, device, batch_size):\n",
    "    \"\"\"\n",
    "    Builds dataloader for training data.\n",
    "    Use tt.Compose and tt.Resize for transformations\n",
    "    :param batch_size: batch_size of the dataloader\n",
    "    :returns: DataLoader object \n",
    "    \"\"\"\n",
    "    \n",
    "    return DeviceDataLoader(\n",
    "        DataLoader(dataset, batch_size=batch_size, drop_last=True),\n",
    "        torch.device(device)\n",
    "    )"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-07T21:47:03.445202Z",
     "iopub.execute_input": "2023-07-07T21:47:03.445642Z",
     "iopub.status.idle": "2023-07-07T21:47:03.455475Z",
     "shell.execute_reply.started": "2023-07-07T21:47:03.445610Z",
     "shell.execute_reply": "2023-07-07T21:47:03.454417Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-07-07T22:15:18.749059400Z",
     "start_time": "2023-07-07T22:15:18.637808600Z"
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "ENCODER = \"mobilenet_v2\"\n",
    "ENCODER_WEIGHTS = \"imagenet\"\n",
    "CLASSES = [\"Glade\"]\n",
    "ACTIVATION = 'sigmoid'\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "RESIZE_SHAPE = 256\n",
    "BATCH_SIZE = 16\n",
    "LOSS_NAME = \"DICE\""
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-07T21:47:03.456993Z",
     "iopub.execute_input": "2023-07-07T21:47:03.457641Z",
     "iopub.status.idle": "2023-07-07T21:47:03.490314Z",
     "shell.execute_reply.started": "2023-07-07T21:47:03.457609Z",
     "shell.execute_reply": "2023-07-07T21:47:03.489446Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-07-07T22:15:20.089838800Z",
     "start_time": "2023-07-07T22:15:18.700444500Z"
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "input_transform = albumentations.Compose([\n",
    "    albumentations.HorizontalFlip(p=0.5),\n",
    "    albumentations.Resize(height=RESIZE_SHAPE, width=RESIZE_SHAPE),\n",
    "    # albumentations.Normalize(),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "input_transform_torch = tt.Compose([\n",
    "        tt.Resize(RESIZE_SHAPE),\n",
    "        tt.ToTensor(),\n",
    "        tt.ConvertImageDtype(torch.float),\n",
    "    ])\n",
    "\n",
    "train_path = \"semantic-seg/train\"\n",
    "\n",
    "train_dataset = GladeDataset(train_path, input_transform)\n",
    "\n",
    "train_dataloader = get_dataloader(train_dataset, DEVICE, BATCH_SIZE)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-07T21:47:03.491824Z",
     "iopub.execute_input": "2023-07-07T21:47:03.492440Z",
     "iopub.status.idle": "2023-07-07T21:47:10.050101Z",
     "shell.execute_reply.started": "2023-07-07T21:47:03.492390Z",
     "shell.execute_reply": "2023-07-07T21:47:10.049010Z"
    },
    "trusted": true,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-07-07T22:15:20.098320100Z"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/517 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c5b0bc67416140779a3358ba3756a10a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "valid_path = \"semantic-seg/valid\"\n",
    "\n",
    "valid_dataset = GladeDataset(valid_path, input_transform)\n",
    "\n",
    "valid_dataloader = get_dataloader(valid_dataset, DEVICE, BATCH_SIZE)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-07T21:47:10.052025Z",
     "iopub.execute_input": "2023-07-07T21:47:10.052400Z",
     "iopub.status.idle": "2023-07-07T21:47:11.920432Z",
     "shell.execute_reply.started": "2023-07-07T21:47:10.052362Z",
     "shell.execute_reply": "2023-07-07T21:47:11.919337Z"
    },
    "trusted": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_path = \"semantic-seg/test\"\n",
    "\n",
    "test_dataset = GladeDataset(test_path, input_transform)\n",
    "\n",
    "test_dataloader = get_dataloader(test_dataset, DEVICE, BATCH_SIZE)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-07T21:47:11.924846Z",
     "iopub.execute_input": "2023-07-07T21:47:11.925175Z",
     "iopub.status.idle": "2023-07-07T21:47:12.899504Z",
     "shell.execute_reply.started": "2023-07-07T21:47:11.925144Z",
     "shell.execute_reply": "2023-07-07T21:47:12.898340Z"
    },
    "trusted": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "    \n",
    "for i in range(6):\n",
    "    plt.subplot(2, 6, i+1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(train_dataset[i][0].permute(1, 2, 0).cpu().numpy())\n",
    "\n",
    "    plt.subplot(2, 6, i+7)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(train_dataset[i][1].numpy())\n",
    "plt.show()\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-07T21:47:12.902943Z",
     "iopub.execute_input": "2023-07-07T21:47:12.903317Z",
     "iopub.status.idle": "2023-07-07T21:47:13.603871Z",
     "shell.execute_reply.started": "2023-07-07T21:47:12.903287Z",
     "shell.execute_reply": "2023-07-07T21:47:13.603039Z"
    },
    "trusted": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "exp_folder = f\"experiments/checkpoints_{RESIZE_SHAPE}x{RESIZE_SHAPE}_{ENCODER}_{ACTIVATION}_{LOSS_NAME}_unet\"\n",
    "try:\n",
    "    os.makedirs(exp_folder)\n",
    "except FileExistsError:\n",
    "    os.rmdir(exp_folder)\n",
    "    os.makedirs(exp_folder)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-07T21:47:13.604908Z",
     "iopub.execute_input": "2023-07-07T21:47:13.606238Z",
     "iopub.status.idle": "2023-07-07T21:47:13.611792Z",
     "shell.execute_reply.started": "2023-07-07T21:47:13.606195Z",
     "shell.execute_reply": "2023-07-07T21:47:13.610910Z"
    },
    "trusted": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = smp.UnetPlusPlus(\n",
    "    encoder_name=ENCODER,\n",
    "    encoder_weights=ENCODER_WEIGHTS,\n",
    "    in_channels=3,  \n",
    "    classes=len(CLASSES)\n",
    ")\n",
    "\n",
    "loss = smp.losses.DiceLoss(mode=\"binary\")\n",
    "loss.__name__ = LOSS_NAME\n",
    "# loss = smp.losses.SoftBCEWithLogitsLoss()\n",
    "# loss.__name__ = LOSS_NAME\n",
    "\n",
    "metrics = [smp.utils.metrics.IoU()]\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "        dict(params=model.parameters(), lr=0.0001),\n",
    "    ])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-07T21:47:13.613575Z",
     "iopub.execute_input": "2023-07-07T21:47:13.614333Z",
     "iopub.status.idle": "2023-07-07T21:47:14.141271Z",
     "shell.execute_reply.started": "2023-07-07T21:47:13.614299Z",
     "shell.execute_reply": "2023-07-07T21:47:14.140285Z"
    },
    "trusted": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.to(\"cuda\")\n",
    "summary(model, (3, 256, 256))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-07T21:47:14.142643Z",
     "iopub.execute_input": "2023-07-07T21:47:14.143489Z",
     "iopub.status.idle": "2023-07-07T21:47:22.016775Z",
     "shell.execute_reply.started": "2023-07-07T21:47:14.143455Z",
     "shell.execute_reply": "2023-07-07T21:47:22.015802Z"
    },
    "trusted": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "train_epoch = smp.utils.train.TrainEpoch(\n",
    "    model,\n",
    "    loss=loss,\n",
    "    metrics=metrics,\n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "valid_epoch = smp.utils.train.ValidEpoch(\n",
    "    model,\n",
    "    loss=loss,\n",
    "    metrics=metrics,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "max_score = 0\n",
    "for i in range(0, 50):\n",
    "\n",
    "    print(\"\\nEpoch: {}\".format(i))\n",
    "    train_logs = train_epoch.run(train_dataloader)\n",
    "    valid_logs = valid_epoch.run(valid_dataloader)\n",
    "\n",
    "    if max_score < valid_logs[\"iou_score\"]:\n",
    "        max_score = valid_logs[\"iou_score\"]\n",
    "        torch.save(\n",
    "            model, os.path.join(exp_folder, f\"best_model_{max_score}_{i}-epoch.pth\")\n",
    "        )\n",
    "        print(\"Model saved!\")\n",
    "\n",
    "    if i == 12:\n",
    "        optimizer.param_groups[0][\"lr\"] = 1e-5\n",
    "        print(\"Decrease decoder learning rate to 1e-5!\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-07T21:47:22.018397Z",
     "iopub.execute_input": "2023-07-07T21:47:22.019024Z",
     "iopub.status.idle": "2023-07-07T21:51:47.597184Z",
     "shell.execute_reply.started": "2023-07-07T21:47:22.018987Z",
     "shell.execute_reply": "2023-07-07T21:51:47.596119Z"
    },
    "trusted": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def predict(model, X_batch):\n",
    "    model.eval()  # testing mode\n",
    "    y_pred = model(X_batch)\n",
    "\n",
    "    return y_pred"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-07T21:51:47.598705Z",
     "iopub.execute_input": "2023-07-07T21:51:47.599611Z",
     "iopub.status.idle": "2023-07-07T21:51:47.604736Z",
     "shell.execute_reply.started": "2023-07-07T21:51:47.599576Z",
     "shell.execute_reply": "2023-07-07T21:51:47.603778Z"
    },
    "trusted": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(18, 18))\n",
    "\n",
    "pred = None\n",
    "for image, mask in test_dataloader:\n",
    "    pred = predict(model=model, X_batch=image)\n",
    "    pred = torch.where(pred > 0.5, 1, 0)\n",
    "    break\n",
    "    \n",
    "for i in range(3):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(test_dataset[i][0].permute(1, 2, 0).cpu().numpy())\n",
    "\n",
    "    plt.subplot(3, 3, i+4)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(test_dataset[i][1].numpy())\n",
    "    \n",
    "    plt.subplot(3, 3, i+7)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(pred[i].permute(1, 2, 0).detach().cpu().numpy())\n",
    "    \n",
    "    \n",
    "plt.subplots_adjust(wspace=0, hspace=0.1)\n",
    "plt.show()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-07T21:51:47.606235Z",
     "iopub.execute_input": "2023-07-07T21:51:47.607206Z",
     "iopub.status.idle": "2023-07-07T21:51:48.740668Z",
     "shell.execute_reply.started": "2023-07-07T21:51:47.607171Z",
     "shell.execute_reply": "2023-07-07T21:51:48.738906Z"
    },
    "trusted": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ручка"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class GladeSegment:\n",
    "    \"\"\" Unet + MobileNet segmentation \"\"\"\n",
    "\n",
    "    def __init__(self, model_path):\n",
    "        self.model = torch.hub.load(None, path=model_path, force_reload=True)\n",
    "\n",
    "    def predict(self, image: np.ndarray):\n",
    "        model.eval()\n",
    "        \n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        image = torch.ToTensor(image)\n",
    "        \n",
    "        pred = self.model(image)\n",
    "        pred = torch.where(pred > 0.5, 1, 0)\n",
    "\n",
    "        result = self.model(image)\n",
    "        result = result.numpy()\n",
    "\n",
    "        return result"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-07T21:51:48.742138Z",
     "iopub.execute_input": "2023-07-07T21:51:48.743080Z",
     "iopub.status.idle": "2023-07-07T21:51:48.750211Z",
     "shell.execute_reply.started": "2023-07-07T21:51:48.743046Z",
     "shell.execute_reply": "2023-07-07T21:51:48.749221Z"
    },
    "trusted": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!ls /kaggle/working/"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-07T21:51:48.751562Z",
     "iopub.execute_input": "2023-07-07T21:51:48.752553Z",
     "iopub.status.idle": "2023-07-07T21:51:50.536979Z",
     "shell.execute_reply.started": "2023-07-07T21:51:48.752521Z",
     "shell.execute_reply": "2023-07-07T21:51:50.535570Z"
    },
    "trusted": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_model = GladeSegment()\n",
    "\n",
    "image_path = \"/kaggle/input/hello-world/test/0301435ff901dc5a3bb4ab900fa5e4c3b9c27632_JPG.rf.3503e2b93cb2eabf78c50230369c4dc1.jpg\""
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-07T21:51:50.538295Z",
     "iopub.status.idle": "2023-07-07T21:51:50.539037Z",
     "shell.execute_reply.started": "2023-07-07T21:51:50.538772Z",
     "shell.execute_reply": "2023-07-07T21:51:50.538799Z"
    },
    "trusted": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ]
}
